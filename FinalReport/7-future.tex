\section{Future Work}

For now the consumer directly talks to the attribute authority with the token issued by the token issuer. Since the consumer is not be trusted we think for the better design, we can reduce current verification steps by letting token issuer fetch all decryption keys from attribute authority for verified users. Since the attribute authority trusts the token issuer and token issuer trusts the consumers, this design can reduce the cost of trust for attribute authority. After all decryption keys fetched by token issuer, the attribute authority can go offline before talking to anyone it doesn't trust (like consumer), which can prevent attribute authority from attack.

Furthermore, thanks to the property of NDN, the data produced by the producer can be stored in in-network storage. To be consistent the synchronization protocol can be applied to these storage. Since the name is the only identity in NDN, it can reduce the workload for producer and achieve a better performance.

Since now there is only library of NDN-ABAC implemented, later we will implemented the concrete application based on the library which is simple. For different entity they only need to create the corresponding components in the code base and call the functions provided. The current integrated test can only prove the logic is correct, but the real performance needed to be verified. Besides, the policy for data is static and we still need the mechanism to update the policy for different data. The policy regression need to be design. For now we have several solution like set the timer for the data packets, which is simple and practical. Or we can add a version attribute and change it whenever the updates made to the data, but it will increase the cost for the decryption key exchange. A proper solution need be made.